{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Day22_作業_Seq2Seq_translator_en_de.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrWWUhFlUprI"
      },
      "source": [
        "# 作業 : 實作英文-德文翻譯機器人\n",
        "***\n",
        "## [作業目標]\n",
        "\n",
        "用 pytorch 實作一個英文-德文翻譯機器人\n",
        "\n",
        "## [作業目標]\n",
        "\n",
        "*   語言資料處理\n",
        "*   使用 LSTM 建構 Encoder: EncoderLSTM\n",
        "*   使用 LSTM 建構 Decoder: DecoderLSTM\n",
        "*   搭建 Sequence to Sequence 模型: Seq2Seq\n",
        "*   撰寫訓練函式\n",
        "*   撰寫測試函式\n",
        "\n",
        "## [問題]\n",
        "\n",
        "在 Colab 實際上執行完這個範例後，請改用 BiLSTM 來建構 Encoder 與 Decoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgPfcYR26SxF"
      },
      "source": [
        "## 安裝 spacy\n",
        "\n",
        "We'll also make use of spaCy to tokenize our data. To install spaCy, follow the instructions here making sure to install both the English and German models with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzjl5xnFTm6l",
        "outputId": "146ec624-b3ed-4e54-cb6b-1c40914201af"
      },
      "source": [
        "!pip uninstall spacy -y\n",
        "!pip install -U spacy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling spacy-3.0.1:\n",
            "  Successfully uninstalled spacy-3.0.1\n",
            "Collecting spacy\n",
            "  Using cached https://files.pythonhosted.org/packages/c5/5d/20f8252a9dfe7057721136d83cecb1ca1e0936b21fd7a0a4889d1d6650a8/spacy-3.0.1-cp36-cp36m-manylinux2014_x86_64.whl\n",
            "Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied, skipping upgrade: thinc<8.1.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (8.0.1)\n",
            "Requirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied, skipping upgrade: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.1)\n",
            "Requirement already satisfied, skipping upgrade: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.7.3)\n",
            "Requirement already satisfied, skipping upgrade: pathy in /usr/local/lib/python3.6/dist-packages (from spacy) (0.3.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied, skipping upgrade: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.11.3)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.4.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (53.0.0)\n",
            "Requirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: contextvars<3,>=2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.0->spacy) (2.4)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses<1.0,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.0->spacy) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pathy->spacy) (3.0.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars<3,>=2.4; python_version < \"3.7\"->thinc<8.1.0,>=8.0.0->spacy) (0.14)\n",
            "Installing collected packages: spacy\n",
            "Successfully installed spacy-3.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyd4LijE7vGo"
      },
      "source": [
        "## 引用需要的模組"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RanKHsWTu-rn"
      },
      "source": [
        "import jieba\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import random\n",
        "# from torchtext.data.metrics import bleu_score\n",
        "from pprint import pprint\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9h9rmgr74Sk"
      },
      "source": [
        "## 下載英文預料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyskUGjGSr-0",
        "scrolled": true,
        "outputId": "4b7b46c5-527f-4fab-f663-ff3e871dd54d"
      },
      "source": [
        "!mkdir ./data\n",
        "!mkdir ./data/multi30k\n",
        "!python -m spacy download en\n",
        "!ls ./data/multi30k -al\n",
        "spacy_english = spacy.load(\"en_core_web_sm\")\n",
        "!ls ./data/multi30k -al"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./data’: File exists\n",
            "mkdir: cannot create directory ‘./data/multi30k’: File exists\n",
            "2021-02-07 07:15:55.933763: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Pleaseuse the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Requirement already satisfied: en-core-web-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl#egg=en_core_web_sm==3.0.0 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from en-core-web-sm==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (53.0.0)\n",
            "Requirement already satisfied: pathy in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic<1.8.0,>=1.7.1->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.4.0)\n",
            "Requirement already satisfied: contextvars<3,>=2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars<3,>=2.4; python_version < \"3.7\"->thinc<8.1.0,>=8.0.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.14)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Feb  7 06:51 .\n",
            "drwxr-xr-x 3 root root 4096 Feb  7 06:51 ..\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Feb  7 06:51 .\n",
            "drwxr-xr-x 3 root root 4096 Feb  7 06:51 ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBestLOF8L4w"
      },
      "source": [
        "## 下載德語語料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Hjr_6AXTRoz",
        "scrolled": true,
        "outputId": "e9451e09-4b3e-4094-9444-ad7951f5f6f1"
      },
      "source": [
        "!python -m spacy download de\n",
        "spacy_de = spacy.load(\"de_core_news_sm\")\n",
        "!ls ./data/multi30k -al"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-07 07:16:02.172049: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'de' are deprecated. Pleaseuse the\n",
            "full pipeline package name 'de_core_news_sm' instead.\u001b[0m\n",
            "Requirement already satisfied: de-core-news-sm==3.0.0 from https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.0.0/de_core_news_sm-3.0.0-py3-none-any.whl#egg=de_core_news_sm==3.0.0 in /usr/local/lib/python3.6/dist-packages (3.0.0)\n",
            "Requirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from de-core-news-sm==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (53.0.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (4.41.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (20.9)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (8.0.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.4.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.5)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.0)\n",
            "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.7.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.0.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.11.3)\n",
            "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.3.2)\n",
            "Requirement already satisfied: pathy in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.3.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4.7)\n",
            "Requirement already satisfied: dataclasses<1.0,>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.8)\n",
            "Requirement already satisfied: contextvars<3,>=2.4; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from thinc<8.1.0,>=8.0.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (2.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (1.1.1)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.6/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (7.1.2)\n",
            "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pathy->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (3.0.0)\n",
            "Requirement already satisfied: immutables>=0.9 in /usr/local/lib/python3.6/dist-packages (from contextvars<3,>=2.4; python_version < \"3.7\"->thinc<8.1.0,>=8.0.0->spacy<3.1.0,>=3.0.0->de-core-news-sm==3.0.0) (0.14)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Feb  7 06:51 .\n",
            "drwxr-xr-x 3 root root 4096 Feb  7 06:51 ..\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK984GbYv8Y-",
        "outputId": "3b71a897-aa5a-4c82-f5f7-3be45504df65"
      },
      "source": [
        "def tokenize_de(text):\n",
        "    return [token.text for token in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_english(text):\n",
        "    return [token.text for token in spacy_english.tokenizer(text)]\n",
        "\n",
        "### Sample Run ###\n",
        "\n",
        "sample_text = \"I love machine learning\"\n",
        "print(tokenize_english(sample_text))\n",
        "\n",
        "german = Field(tokenize=tokenize_de, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "english = Field(tokenize=tokenize_english, lower=True,\n",
        "               init_token=\"<sos>\", eos_token=\"<eos>\")\n",
        "\n",
        "train_data, valid_data, test_data = Multi30k.splits(exts = (\".en\", \".en\"),\n",
        "                                                    fields=(german, english))\n",
        "\n",
        "german.build_vocab(train_data, max_size=10000, min_freq=3)\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=3)\n",
        "\n",
        "print(f\"Unique tokens in source (german) vocabulary: {len(german.vocab)}\")\n",
        "print(f\"Unique tokens in target (en) vocabulary: {len(english.vocab)}\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', 'love', 'machine', 'learning']\n",
            "Unique tokens in source (german) vocabulary: 4587\n",
            "Unique tokens in target (en) vocabulary: 4556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ3fiLno60K_"
      },
      "source": [
        "word_2_idx = english.vocab.stoi\n",
        "idx_2_word = {}\n",
        "for k,v in word_2_idx.items():\n",
        "    idx_2_word[v] = k"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WunTmSIJzBaC",
        "outputId": "d2f19d2c-663b-488f-dc30-46be7af7a873"
      },
      "source": [
        "print(f\"Number of training examples: {len(train_data.examples)}\")\n",
        "print(f\"Number of validation examples: {len(valid_data.examples)}\")\n",
        "print(f\"Number of testing examples: {len(test_data.examples)}\")\n",
        "\n",
        "print(train_data[5].__dict__.keys())\n",
        "pprint(train_data[5].__dict__.values())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 29000\n",
            "Number of validation examples: 1014\n",
            "Number of testing examples: 1000\n",
            "dict_keys(['src', 'trg'])\n",
            "dict_values([['a', 'man', 'in', 'green', 'holds', 'a', 'guitar', 'while', 'the', 'other', 'man', 'observes', 'his', 'shirt', '.'], ['a', 'man', 'in', 'green', 'holds', 'a', 'guitar', 'while', 'the', 'other', 'man', 'observes', 'his', 'shirt', '.']])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRGP9EsizRRN"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits((train_data, valid_data, test_data), \n",
        "                                                                      batch_size = BATCH_SIZE, \n",
        "                                                                      sort_within_batch=True,\n",
        "                                                                      sort_key=lambda x: len(x.src),\n",
        "                                                                      device = device)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3nozOT8zdeD",
        "outputId": "9aab0a3f-e258-4ef5-bbaf-d491de7147bf"
      },
      "source": [
        "count = 0\n",
        "max_len_eng = []\n",
        "max_len_ger = []\n",
        "for data in train_data:\n",
        "  max_len_ger.append(len(data.src))\n",
        "  max_len_eng.append(len(data.trg))\n",
        "  if count < 10 :\n",
        "    print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
        "    print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n",
        "    print()\n",
        "  count += 1\n",
        "\n",
        "print(\"Maximum Length of English sentence {} and German sentence {} in the dataset\".format(max(max_len_eng),max(max_len_ger)))\n",
        "print(\"Minimum Length of English sentence {} and German sentence {} in the dataset\".format(min(max_len_eng),min(max_len_ger)))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "German -  two young , white males are outside near many bushes .  Length -  11\n",
            "English -  two young , white males are outside near many bushes .  Length -  11\n",
            "\n",
            "German -  several men in hard hats are operating a giant pulley system .  Length -  12\n",
            "English -  several men in hard hats are operating a giant pulley system .  Length -  12\n",
            "\n",
            "German -  a little girl climbing into a wooden playhouse .  Length -  9\n",
            "English -  a little girl climbing into a wooden playhouse .  Length -  9\n",
            "\n",
            "German -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n",
            "English -  a man in a blue shirt is standing on a ladder cleaning a window .  Length -  15\n",
            "\n",
            "German -  two men are at the stove preparing food .  Length -  9\n",
            "English -  two men are at the stove preparing food .  Length -  9\n",
            "\n",
            "German -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n",
            "English -  a man in green holds a guitar while the other man observes his shirt .  Length -  15\n",
            "\n",
            "German -  a man is smiling at a stuffed lion  Length -  8\n",
            "English -  a man is smiling at a stuffed lion  Length -  8\n",
            "\n",
            "German -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n",
            "English -  a trendy girl talking on her cellphone while gliding slowly down the street .  Length -  14\n",
            "\n",
            "German -  a woman with a large purse is walking by a gate .  Length -  12\n",
            "English -  a woman with a large purse is walking by a gate .  Length -  12\n",
            "\n",
            "German -  boys dancing on poles in the middle of the night .  Length -  11\n",
            "English -  boys dancing on poles in the middle of the night .  Length -  11\n",
            "\n",
            "Maximum Length of English sentence 41 and German sentence 40 in the dataset\n",
            "Minimum Length of English sentence 4 and German sentence 4 in the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE_S5yMdwRsT",
        "outputId": "5500417c-bec6-4971-9746-aefbf7b06a41"
      },
      "source": [
        "count = 0\n",
        "for data in train_iterator:\n",
        "  if count < 1 :\n",
        "    print(\"Shapes\", data.src.shape, data.trg.shape)\n",
        "    print()\n",
        "    print(\"German - \",*data.src, \" Length - \", len(data.src))\n",
        "    print()\n",
        "    print(\"English - \",*data.trg, \" Length - \", len(data.trg))\n",
        "    temp_ger = data.src\n",
        "    temp_eng = data.trg\n",
        "    count += 1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shapes torch.Size([14, 32]) torch.Size([16, 32])\n",
            "\n",
            "German -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([  4,   4,  21,   4,   4,   4,   4,   4,   4,  16,   4, 953,   7,   4,\n",
            "        172,   4,   4,   4,  16,  16,   4,   4, 190,   4,   4,   4,   4,   4,\n",
            "         46,  38,   4,   4], device='cuda:0') tensor([1161,   32,  144,   63,    9,  151,    9,    9,   15,   49,   51,   19,\n",
            "         490,   34,   17,   38,    9,  423,  100,   23,   23,   35,   22,    9,\n",
            "          15,  691,  119,   15,  123,   12,    9,  177], device='cuda:0') tensor([  9,  13,   9, 164,  10,  34,   6, 129,   6,  17,  32, 147,   9, 751,\n",
            "         46,  12,   6, 185,  31,  62,  34, 598, 145,  11,  88,  32, 133,  13,\n",
            "        125,  23,  22, 638], device='cuda:0') tensor([   6,    0,   36,    4,   41,    6,    4,   53,    4,   31,   22,   20,\n",
            "           6,   20,   62,   19,    4, 1204,    6,   37,    8,    6,   37,   34,\n",
            "           8,   22,   10, 2612,  120,  317,   50,    6], device='cuda:0') tensor([   4,   11,   92,  259,   18,    4,   24,    7,  193,   20,    4,   93,\n",
            "           7,    4,    6, 3740,   24,  111,   61,   13,    7,    7,   56,   10,\n",
            "           7,    4, 2050, 1070,    4,   13,  174,    4], device='cuda:0') tensor([  29,  302,    4,  796,    7,  135,   67,  115,  313,    4,   24,    6,\n",
            "        1958, 2185,  607,    4,   25,    4,  397,  284,   86,  101,    6,   54,\n",
            "        1045, 1753,   48,  457,    0, 1352,   13,   50], device='cuda:0') tensor([  25, 3028,  618,   70,   42, 1094,  166,   36,   10,   93,  918,  302,\n",
            "          10,  220,  331,  571,   10, 1110,   13, 1451,   78, 2795,    7,   53,\n",
            "          70,  683,  632,   90,  105,   11,   27,   13], device='cuda:0') tensor([2028,  961,  296,   18,   12,   10, 2835,    6,   36,  126,   10, 4082,\n",
            "           0,   21,    8,   12,   36,  199, 1755,    6,   68,   18,  114,  117,\n",
            "          18,  692,    6,  333,   56,    0,  259,   89], device='cuda:0') tensor([ 460,    4,   12,    4,    4,  726,   13,    4,    8,  127,   36,  397,\n",
            "          18,  246,    4, 1050,    8,   20,    8,   21,    7,    4,   13,    8,\n",
            "           4,    6,   29,   20,   12,  584,    6,  362], device='cuda:0') tensor([  85, 2260,   50,   26, 1406,   11,   16,  569,    4,    8,   48, 2478,\n",
            "          27,  347,  119,   89,   21,    4,    7,  700,  218,  207, 4462,    7,\n",
            "         261,    4,   11,    4,    4,    8,    7,   67], device='cuda:0') tensor([ 807, 1323, 3710, 2079,  181,  880,   62,  375,  269, 1617,  958, 3768,\n",
            "        1075,  424,   84, 2858, 1006,  553,   93,  170,  557,   66,   47,  179,\n",
            "          39,  810,   33,   93,   76,   39,   39,  779], device='cuda:0') tensor([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
            "        5, 5, 5, 5, 5, 5, 5, 5], device='cuda:0') tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
            "        3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0')  Length -  14\n",
            "\n",
            "English -  tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0') tensor([  4,   4,  21,   4,   4,   4,   4,   4,   4,  16,   4, 963,   7,   4,\n",
            "        176,   4,   4,   4,  16,  16,   4,   4, 196,   4,   4,   4,   4,   4,\n",
            "         48,  38,   4,   4], device='cuda:0') tensor([163,  33, 145,  64,   9, 153,   9,   9,  14,  50,  53,  19, 491,  34,\n",
            "         17,  38,   9, 429, 104,  24,  24,  35,  22,   9,  14, 122, 123,  14,\n",
            "        127,  12,   9, 183], device='cuda:0') tensor([ 42,  13,   9, 169,  10,  34,   6, 133,   6,  17,  33, 150,   9, 759,\n",
            "         48,  12,   6, 191,  32,  63,  34, 601, 148,  11,  89,  42, 135,  13,\n",
            "        128,  24,  22, 648], device='cuda:0') tensor([ 210,    0,   36,    4,   41,    6,    4,   54,    4,   32,   22,   20,\n",
            "           6,   20,   63,   19,    4, 1213,    6,   37,    8,    6,   37,   34,\n",
            "           8,  210,   10, 2611,  124,  326,   52,    6], device='cuda:0') tensor([   9,   11,   93,  264,   18,    4,   25,    7,  194,   20,    4,   94,\n",
            "           7,    4,    6, 3727,   25,  111,   61,   13,    7,    7,   57,   10,\n",
            "           7,   33, 2049,  867,    4,   13,  179,    4], device='cuda:0') tensor([   6,  307,    4,  627,    7,  138,   67,  116,  317,    4,   25,    6,\n",
            "        1962, 2186,  603,    4,   23,    4,  401,  289,   88,  103,    6,   56,\n",
            "        1048,   22,   49,  122,    0, 1359,   13,   52], device='cuda:0') tensor([   4, 3030,  612,   71,   43, 1097,  173,   36,   10,   94,  924,  307,\n",
            "          10,  226,  338,  573,   10, 1112,   13, 1461,   79, 2799,    7,   54,\n",
            "          71,    4,  639,   42,  108,   11,   27,   13], device='cuda:0') tensor([  29,  972,  298,   18,   12,   10, 2843,    6,   36,  129,   10, 3430,\n",
            "           0,   21,    8,   12,   36,  198, 1762,    6,   69,   18,  118,  121,\n",
            "          18, 1760,    6,   97,   57,    0,  264,   90], device='cuda:0') tensor([  23,    4,   12,    4,    4,  734,   13,    4,    8,  130,   36,   42,\n",
            "          18,  253,    4, 1054,    8,   20,    8,   21,    7,    4,   13,    8,\n",
            "           4,  692,   29,   91,   12,  586,    6,  367], device='cuda:0') tensor([2027, 2112,   52,   26, 1410,   11,   16,  571,    4,    8,   49,   51,\n",
            "          27,  355,  123,   90,   21,    4,    7,  709,  225,  213, 4431,    7,\n",
            "         267,  698,   11,  341,    4,    8,    7,   67], device='cuda:0') tensor([ 457, 1327, 3698, 2075,  187,  883,   63,  381,  274, 1626,  968,  401,\n",
            "        1081,  430,   85, 2866, 1016,  560,   94,  177,  563,   68,   47,  185,\n",
            "          39,    6,   31,   20,   77,   39,   39,  772], device='cuda:0') tensor([  86,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5, 2474,\n",
            "           5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,    5,\n",
            "           5,    4,    5,    4,    5,    5,    5,    5], device='cuda:0') tensor([ 810,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3, 3755,\n",
            "           3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,    3,\n",
            "           3,  817,    3,   94,    3,    3,    3,    3], device='cuda:0') tensor([5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 5, 1, 5, 1, 1, 1, 1], device='cuda:0') tensor([3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 3, 1, 3, 1, 1, 1, 1], device='cuda:0')  Length -  16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSP5RchXyuaz"
      },
      "source": [
        "temp_eng_idx = (temp_eng).cpu().detach().numpy()\n",
        "temp_ger_idx = (temp_ger).cpu().detach().numpy()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "tgAmQS4I6k9v",
        "outputId": "d0010569-ef28-4d6c-a1af-33e3cb907b14"
      },
      "source": [
        "\n",
        "df_eng_idx = pd.DataFrame(data = temp_eng_idx, columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n",
        "df_eng_idx.index.name = 'Time Steps'\n",
        "df_eng_idx.index = df_eng_idx.index + 1 \n",
        "# df_eng_idx.to_csv('/content/idx.csv')\n",
        "df_eng_idx\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S_1</th>\n",
              "      <th>S_2</th>\n",
              "      <th>S_3</th>\n",
              "      <th>S_4</th>\n",
              "      <th>S_5</th>\n",
              "      <th>S_6</th>\n",
              "      <th>S_7</th>\n",
              "      <th>S_8</th>\n",
              "      <th>S_9</th>\n",
              "      <th>S_10</th>\n",
              "      <th>S_11</th>\n",
              "      <th>S_12</th>\n",
              "      <th>S_13</th>\n",
              "      <th>S_14</th>\n",
              "      <th>S_15</th>\n",
              "      <th>S_16</th>\n",
              "      <th>S_17</th>\n",
              "      <th>S_18</th>\n",
              "      <th>S_19</th>\n",
              "      <th>S_20</th>\n",
              "      <th>S_21</th>\n",
              "      <th>S_22</th>\n",
              "      <th>S_23</th>\n",
              "      <th>S_24</th>\n",
              "      <th>S_25</th>\n",
              "      <th>S_26</th>\n",
              "      <th>S_27</th>\n",
              "      <th>S_28</th>\n",
              "      <th>S_29</th>\n",
              "      <th>S_30</th>\n",
              "      <th>S_31</th>\n",
              "      <th>S_32</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Steps</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>963</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>176</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>196</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>48</td>\n",
              "      <td>38</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>163</td>\n",
              "      <td>33</td>\n",
              "      <td>145</td>\n",
              "      <td>64</td>\n",
              "      <td>9</td>\n",
              "      <td>153</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>50</td>\n",
              "      <td>53</td>\n",
              "      <td>19</td>\n",
              "      <td>491</td>\n",
              "      <td>34</td>\n",
              "      <td>17</td>\n",
              "      <td>38</td>\n",
              "      <td>9</td>\n",
              "      <td>429</td>\n",
              "      <td>104</td>\n",
              "      <td>24</td>\n",
              "      <td>24</td>\n",
              "      <td>35</td>\n",
              "      <td>22</td>\n",
              "      <td>9</td>\n",
              "      <td>14</td>\n",
              "      <td>122</td>\n",
              "      <td>123</td>\n",
              "      <td>14</td>\n",
              "      <td>127</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>13</td>\n",
              "      <td>9</td>\n",
              "      <td>169</td>\n",
              "      <td>10</td>\n",
              "      <td>34</td>\n",
              "      <td>6</td>\n",
              "      <td>133</td>\n",
              "      <td>6</td>\n",
              "      <td>17</td>\n",
              "      <td>33</td>\n",
              "      <td>150</td>\n",
              "      <td>9</td>\n",
              "      <td>759</td>\n",
              "      <td>48</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>191</td>\n",
              "      <td>32</td>\n",
              "      <td>63</td>\n",
              "      <td>34</td>\n",
              "      <td>601</td>\n",
              "      <td>148</td>\n",
              "      <td>11</td>\n",
              "      <td>89</td>\n",
              "      <td>42</td>\n",
              "      <td>135</td>\n",
              "      <td>13</td>\n",
              "      <td>128</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>210</td>\n",
              "      <td>0</td>\n",
              "      <td>36</td>\n",
              "      <td>4</td>\n",
              "      <td>41</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>54</td>\n",
              "      <td>4</td>\n",
              "      <td>32</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "      <td>6</td>\n",
              "      <td>20</td>\n",
              "      <td>63</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>1213</td>\n",
              "      <td>6</td>\n",
              "      <td>37</td>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>37</td>\n",
              "      <td>34</td>\n",
              "      <td>8</td>\n",
              "      <td>210</td>\n",
              "      <td>10</td>\n",
              "      <td>2611</td>\n",
              "      <td>124</td>\n",
              "      <td>326</td>\n",
              "      <td>52</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>9</td>\n",
              "      <td>11</td>\n",
              "      <td>93</td>\n",
              "      <td>264</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>7</td>\n",
              "      <td>194</td>\n",
              "      <td>20</td>\n",
              "      <td>4</td>\n",
              "      <td>94</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>3727</td>\n",
              "      <td>25</td>\n",
              "      <td>111</td>\n",
              "      <td>61</td>\n",
              "      <td>13</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>57</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>2049</td>\n",
              "      <td>867</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>179</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>307</td>\n",
              "      <td>4</td>\n",
              "      <td>627</td>\n",
              "      <td>7</td>\n",
              "      <td>138</td>\n",
              "      <td>67</td>\n",
              "      <td>116</td>\n",
              "      <td>317</td>\n",
              "      <td>4</td>\n",
              "      <td>25</td>\n",
              "      <td>6</td>\n",
              "      <td>1962</td>\n",
              "      <td>2186</td>\n",
              "      <td>603</td>\n",
              "      <td>4</td>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>401</td>\n",
              "      <td>289</td>\n",
              "      <td>88</td>\n",
              "      <td>103</td>\n",
              "      <td>6</td>\n",
              "      <td>56</td>\n",
              "      <td>1048</td>\n",
              "      <td>22</td>\n",
              "      <td>49</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "      <td>1359</td>\n",
              "      <td>13</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>4</td>\n",
              "      <td>3030</td>\n",
              "      <td>612</td>\n",
              "      <td>71</td>\n",
              "      <td>43</td>\n",
              "      <td>1097</td>\n",
              "      <td>173</td>\n",
              "      <td>36</td>\n",
              "      <td>10</td>\n",
              "      <td>94</td>\n",
              "      <td>924</td>\n",
              "      <td>307</td>\n",
              "      <td>10</td>\n",
              "      <td>226</td>\n",
              "      <td>338</td>\n",
              "      <td>573</td>\n",
              "      <td>10</td>\n",
              "      <td>1112</td>\n",
              "      <td>13</td>\n",
              "      <td>1461</td>\n",
              "      <td>79</td>\n",
              "      <td>2799</td>\n",
              "      <td>7</td>\n",
              "      <td>54</td>\n",
              "      <td>71</td>\n",
              "      <td>4</td>\n",
              "      <td>639</td>\n",
              "      <td>42</td>\n",
              "      <td>108</td>\n",
              "      <td>11</td>\n",
              "      <td>27</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>29</td>\n",
              "      <td>972</td>\n",
              "      <td>298</td>\n",
              "      <td>18</td>\n",
              "      <td>12</td>\n",
              "      <td>10</td>\n",
              "      <td>2843</td>\n",
              "      <td>6</td>\n",
              "      <td>36</td>\n",
              "      <td>129</td>\n",
              "      <td>10</td>\n",
              "      <td>3430</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>8</td>\n",
              "      <td>12</td>\n",
              "      <td>36</td>\n",
              "      <td>198</td>\n",
              "      <td>1762</td>\n",
              "      <td>6</td>\n",
              "      <td>69</td>\n",
              "      <td>18</td>\n",
              "      <td>118</td>\n",
              "      <td>121</td>\n",
              "      <td>18</td>\n",
              "      <td>1760</td>\n",
              "      <td>6</td>\n",
              "      <td>97</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>264</td>\n",
              "      <td>90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>23</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>734</td>\n",
              "      <td>13</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>130</td>\n",
              "      <td>36</td>\n",
              "      <td>42</td>\n",
              "      <td>18</td>\n",
              "      <td>253</td>\n",
              "      <td>4</td>\n",
              "      <td>1054</td>\n",
              "      <td>8</td>\n",
              "      <td>20</td>\n",
              "      <td>8</td>\n",
              "      <td>21</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>692</td>\n",
              "      <td>29</td>\n",
              "      <td>91</td>\n",
              "      <td>12</td>\n",
              "      <td>586</td>\n",
              "      <td>6</td>\n",
              "      <td>367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2027</td>\n",
              "      <td>2112</td>\n",
              "      <td>52</td>\n",
              "      <td>26</td>\n",
              "      <td>1410</td>\n",
              "      <td>11</td>\n",
              "      <td>16</td>\n",
              "      <td>571</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>49</td>\n",
              "      <td>51</td>\n",
              "      <td>27</td>\n",
              "      <td>355</td>\n",
              "      <td>123</td>\n",
              "      <td>90</td>\n",
              "      <td>21</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>709</td>\n",
              "      <td>225</td>\n",
              "      <td>213</td>\n",
              "      <td>4431</td>\n",
              "      <td>7</td>\n",
              "      <td>267</td>\n",
              "      <td>698</td>\n",
              "      <td>11</td>\n",
              "      <td>341</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>457</td>\n",
              "      <td>1327</td>\n",
              "      <td>3698</td>\n",
              "      <td>2075</td>\n",
              "      <td>187</td>\n",
              "      <td>883</td>\n",
              "      <td>63</td>\n",
              "      <td>381</td>\n",
              "      <td>274</td>\n",
              "      <td>1626</td>\n",
              "      <td>968</td>\n",
              "      <td>401</td>\n",
              "      <td>1081</td>\n",
              "      <td>430</td>\n",
              "      <td>85</td>\n",
              "      <td>2866</td>\n",
              "      <td>1016</td>\n",
              "      <td>560</td>\n",
              "      <td>94</td>\n",
              "      <td>177</td>\n",
              "      <td>563</td>\n",
              "      <td>68</td>\n",
              "      <td>47</td>\n",
              "      <td>185</td>\n",
              "      <td>39</td>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "      <td>20</td>\n",
              "      <td>77</td>\n",
              "      <td>39</td>\n",
              "      <td>39</td>\n",
              "      <td>772</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>86</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>2474</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>810</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3755</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>817</td>\n",
              "      <td>3</td>\n",
              "      <td>94</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             S_1   S_2   S_3   S_4   S_5  ...  S_28  S_29  S_30  S_31  S_32\n",
              "Time Steps                                ...                              \n",
              "1              2     2     2     2     2  ...     2     2     2     2     2\n",
              "2              4     4    21     4     4  ...     4    48    38     4     4\n",
              "3            163    33   145    64     9  ...    14   127    12     9   183\n",
              "4             42    13     9   169    10  ...    13   128    24    22   648\n",
              "5            210     0    36     4    41  ...  2611   124   326    52     6\n",
              "6              9    11    93   264    18  ...   867     4    13   179     4\n",
              "7              6   307     4   627     7  ...   122     0  1359    13    52\n",
              "8              4  3030   612    71    43  ...    42   108    11    27    13\n",
              "9             29   972   298    18    12  ...    97    57     0   264    90\n",
              "10            23     4    12     4     4  ...    91    12   586     6   367\n",
              "11          2027  2112    52    26  1410  ...   341     4     8     7    67\n",
              "12           457  1327  3698  2075   187  ...    20    77    39    39   772\n",
              "13            86     5     5     5     5  ...     4     5     5     5     5\n",
              "14           810     3     3     3     3  ...    94     3     3     3     3\n",
              "15             5     1     1     1     1  ...     5     1     1     1     1\n",
              "16             3     1     1     1     1  ...     3     1     1     1     1\n",
              "\n",
              "[16 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 587
        },
        "id": "vXy1431M6o02",
        "outputId": "573fc5ce-0618-4809-b374-5a6f7f6fbc86"
      },
      "source": [
        "df_eng_word = pd.DataFrame(columns = [str(\"S_\")+str(x) for x in np.arange(1, 33)])\n",
        "df_eng_word = df_eng_idx.replace(idx_2_word)\n",
        "# df_eng_word.to_csv('/content/Words.csv')\n",
        "df_eng_word"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>S_1</th>\n",
              "      <th>S_2</th>\n",
              "      <th>S_3</th>\n",
              "      <th>S_4</th>\n",
              "      <th>S_5</th>\n",
              "      <th>S_6</th>\n",
              "      <th>S_7</th>\n",
              "      <th>S_8</th>\n",
              "      <th>S_9</th>\n",
              "      <th>S_10</th>\n",
              "      <th>S_11</th>\n",
              "      <th>S_12</th>\n",
              "      <th>S_13</th>\n",
              "      <th>S_14</th>\n",
              "      <th>S_15</th>\n",
              "      <th>S_16</th>\n",
              "      <th>S_17</th>\n",
              "      <th>S_18</th>\n",
              "      <th>S_19</th>\n",
              "      <th>S_20</th>\n",
              "      <th>S_21</th>\n",
              "      <th>S_22</th>\n",
              "      <th>S_23</th>\n",
              "      <th>S_24</th>\n",
              "      <th>S_25</th>\n",
              "      <th>S_26</th>\n",
              "      <th>S_27</th>\n",
              "      <th>S_28</th>\n",
              "      <th>S_29</th>\n",
              "      <th>S_30</th>\n",
              "      <th>S_31</th>\n",
              "      <th>S_32</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time Steps</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "      <td>&lt;sos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>an</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>two</td>\n",
              "      <td>a</td>\n",
              "      <td>seven</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>there</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>two</td>\n",
              "      <td>two</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>kids</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>three</td>\n",
              "      <td>group</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>long</td>\n",
              "      <td>girl</td>\n",
              "      <td>old</td>\n",
              "      <td>person</td>\n",
              "      <td>man</td>\n",
              "      <td>baby</td>\n",
              "      <td>man</td>\n",
              "      <td>man</td>\n",
              "      <td>woman</td>\n",
              "      <td>women</td>\n",
              "      <td>little</td>\n",
              "      <td>people</td>\n",
              "      <td>bearded</td>\n",
              "      <td>boy</td>\n",
              "      <td>are</td>\n",
              "      <td>group</td>\n",
              "      <td>man</td>\n",
              "      <td>cowboy</td>\n",
              "      <td>girls</td>\n",
              "      <td>young</td>\n",
              "      <td>young</td>\n",
              "      <td>dog</td>\n",
              "      <td>wearing</td>\n",
              "      <td>man</td>\n",
              "      <td>woman</td>\n",
              "      <td>blond</td>\n",
              "      <td>soccer</td>\n",
              "      <td>woman</td>\n",
              "      <td>boys</td>\n",
              "      <td>of</td>\n",
              "      <td>man</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-</td>\n",
              "      <td>with</td>\n",
              "      <td>man</td>\n",
              "      <td>doing</td>\n",
              "      <td>is</td>\n",
              "      <td>boy</td>\n",
              "      <td>in</td>\n",
              "      <td>smiling</td>\n",
              "      <td>in</td>\n",
              "      <td>are</td>\n",
              "      <td>girl</td>\n",
              "      <td>sit</td>\n",
              "      <td>man</td>\n",
              "      <td>swings</td>\n",
              "      <td>three</td>\n",
              "      <td>of</td>\n",
              "      <td>in</td>\n",
              "      <td>being</td>\n",
              "      <td>sitting</td>\n",
              "      <td>children</td>\n",
              "      <td>boy</td>\n",
              "      <td>leaps</td>\n",
              "      <td>shorts</td>\n",
              "      <td>and</td>\n",
              "      <td>stands</td>\n",
              "      <td>-</td>\n",
              "      <td>game</td>\n",
              "      <td>with</td>\n",
              "      <td>play</td>\n",
              "      <td>young</td>\n",
              "      <td>wearing</td>\n",
              "      <td>skier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>haired</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>standing</td>\n",
              "      <td>a</td>\n",
              "      <td>walking</td>\n",
              "      <td>in</td>\n",
              "      <td>a</td>\n",
              "      <td>for</td>\n",
              "      <td>a</td>\n",
              "      <td>sitting</td>\n",
              "      <td>wearing</td>\n",
              "      <td>at</td>\n",
              "      <td>in</td>\n",
              "      <td>at</td>\n",
              "      <td>children</td>\n",
              "      <td>people</td>\n",
              "      <td>a</td>\n",
              "      <td>thrown</td>\n",
              "      <td>in</td>\n",
              "      <td>playing</td>\n",
              "      <td>on</td>\n",
              "      <td>in</td>\n",
              "      <td>playing</td>\n",
              "      <td>boy</td>\n",
              "      <td>on</td>\n",
              "      <td>haired</td>\n",
              "      <td>is</td>\n",
              "      <td>thick</td>\n",
              "      <td>along</td>\n",
              "      <td>adults</td>\n",
              "      <td>green</td>\n",
              "      <td>in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>man</td>\n",
              "      <td>and</td>\n",
              "      <td>behind</td>\n",
              "      <td>skateboard</td>\n",
              "      <td>to</td>\n",
              "      <td>a</td>\n",
              "      <td>white</td>\n",
              "      <td>the</td>\n",
              "      <td>striped</td>\n",
              "      <td>at</td>\n",
              "      <td>a</td>\n",
              "      <td>table</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>in</td>\n",
              "      <td>surround</td>\n",
              "      <td>white</td>\n",
              "      <td>off</td>\n",
              "      <td>brown</td>\n",
              "      <td>with</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>outside</td>\n",
              "      <td>is</td>\n",
              "      <td>the</td>\n",
              "      <td>girl</td>\n",
              "      <td>played</td>\n",
              "      <td>curly</td>\n",
              "      <td>a</td>\n",
              "      <td>with</td>\n",
              "      <td>jumps</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>in</td>\n",
              "      <td>metal</td>\n",
              "      <td>a</td>\n",
              "      <td>flip</td>\n",
              "      <td>the</td>\n",
              "      <td>car</td>\n",
              "      <td>hat</td>\n",
              "      <td>camera</td>\n",
              "      <td>sweater</td>\n",
              "      <td>a</td>\n",
              "      <td>white</td>\n",
              "      <td>in</td>\n",
              "      <td>trolley</td>\n",
              "      <td>pinata</td>\n",
              "      <td>sports</td>\n",
              "      <td>a</td>\n",
              "      <td>shirt</td>\n",
              "      <td>a</td>\n",
              "      <td>chairs</td>\n",
              "      <td>big</td>\n",
              "      <td>beach</td>\n",
              "      <td>air</td>\n",
              "      <td>in</td>\n",
              "      <td>looking</td>\n",
              "      <td>curb</td>\n",
              "      <td>wearing</td>\n",
              "      <td>by</td>\n",
              "      <td>blond</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>buckets</td>\n",
              "      <td>with</td>\n",
              "      <td>green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a</td>\n",
              "      <td>earrings</td>\n",
              "      <td>basket</td>\n",
              "      <td>next</td>\n",
              "      <td>front</td>\n",
              "      <td>seat</td>\n",
              "      <td>watching</td>\n",
              "      <td>standing</td>\n",
              "      <td>is</td>\n",
              "      <td>table</td>\n",
              "      <td>blouse</td>\n",
              "      <td>metal</td>\n",
              "      <td>is</td>\n",
              "      <td>during</td>\n",
              "      <td>uniforms</td>\n",
              "      <td>bunch</td>\n",
              "      <td>is</td>\n",
              "      <td>bucking</td>\n",
              "      <td>with</td>\n",
              "      <td>wheels</td>\n",
              "      <td>running</td>\n",
              "      <td>parallel</td>\n",
              "      <td>the</td>\n",
              "      <td>for</td>\n",
              "      <td>next</td>\n",
              "      <td>a</td>\n",
              "      <td>teams</td>\n",
              "      <td>-</td>\n",
              "      <td>wall</td>\n",
              "      <td>and</td>\n",
              "      <td>his</td>\n",
              "      <td>with</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>blue</td>\n",
              "      <td>enjoys</td>\n",
              "      <td>full</td>\n",
              "      <td>to</td>\n",
              "      <td>of</td>\n",
              "      <td>is</td>\n",
              "      <td>seagulls</td>\n",
              "      <td>in</td>\n",
              "      <td>standing</td>\n",
              "      <td>together</td>\n",
              "      <td>is</td>\n",
              "      <td>fold</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>an</td>\n",
              "      <td>on</td>\n",
              "      <td>of</td>\n",
              "      <td>standing</td>\n",
              "      <td>horse</td>\n",
              "      <td>beverages</td>\n",
              "      <td>in</td>\n",
              "      <td>into</td>\n",
              "      <td>to</td>\n",
              "      <td>park</td>\n",
              "      <td>something</td>\n",
              "      <td>to</td>\n",
              "      <td>beanie</td>\n",
              "      <td>in</td>\n",
              "      <td>hair</td>\n",
              "      <td>outside</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>skateboard</td>\n",
              "      <td>pink</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>shirt</td>\n",
              "      <td>a</td>\n",
              "      <td>of</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>asleep</td>\n",
              "      <td>with</td>\n",
              "      <td>a</td>\n",
              "      <td>on</td>\n",
              "      <td>working</td>\n",
              "      <td>standing</td>\n",
              "      <td>-</td>\n",
              "      <td>to</td>\n",
              "      <td>outdoor</td>\n",
              "      <td>a</td>\n",
              "      <td>inflatable</td>\n",
              "      <td>on</td>\n",
              "      <td>at</td>\n",
              "      <td>on</td>\n",
              "      <td>an</td>\n",
              "      <td>the</td>\n",
              "      <td>a</td>\n",
              "      <td>with</td>\n",
              "      <td>on</td>\n",
              "      <td>a</td>\n",
              "      <td>blowing</td>\n",
              "      <td>blue</td>\n",
              "      <td>sits</td>\n",
              "      <td>of</td>\n",
              "      <td>wet</td>\n",
              "      <td>in</td>\n",
              "      <td>flowers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>juggles</td>\n",
              "      <td>cherry</td>\n",
              "      <td>green</td>\n",
              "      <td>black</td>\n",
              "      <td>conference</td>\n",
              "      <td>and</td>\n",
              "      <td>two</td>\n",
              "      <td>parking</td>\n",
              "      <td>a</td>\n",
              "      <td>on</td>\n",
              "      <td>by</td>\n",
              "      <td>up</td>\n",
              "      <td>his</td>\n",
              "      <td>family</td>\n",
              "      <td>soccer</td>\n",
              "      <td>pink</td>\n",
              "      <td>an</td>\n",
              "      <td>a</td>\n",
              "      <td>the</td>\n",
              "      <td>urban</td>\n",
              "      <td>ocean</td>\n",
              "      <td>tennis</td>\n",
              "      <td>sprinkling</td>\n",
              "      <td>the</td>\n",
              "      <td>busy</td>\n",
              "      <td>bubbles</td>\n",
              "      <td>and</td>\n",
              "      <td>outdoors</td>\n",
              "      <td>a</td>\n",
              "      <td>on</td>\n",
              "      <td>the</td>\n",
              "      <td>hat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>six</td>\n",
              "      <td>indoors</td>\n",
              "      <td>stalks</td>\n",
              "      <td>trashcan</td>\n",
              "      <td>room</td>\n",
              "      <td>crying</td>\n",
              "      <td>children</td>\n",
              "      <td>lot</td>\n",
              "      <td>hill</td>\n",
              "      <td>crafts</td>\n",
              "      <td>books</td>\n",
              "      <td>chairs</td>\n",
              "      <td>fans</td>\n",
              "      <td>party</td>\n",
              "      <td>field</td>\n",
              "      <td>stars</td>\n",
              "      <td>airplane</td>\n",
              "      <td>rodeo</td>\n",
              "      <td>table</td>\n",
              "      <td>area</td>\n",
              "      <td>waves</td>\n",
              "      <td>ball</td>\n",
              "      <td>water</td>\n",
              "      <td>ground</td>\n",
              "      <td>street</td>\n",
              "      <td>in</td>\n",
              "      <td>red</td>\n",
              "      <td>at</td>\n",
              "      <td>building</td>\n",
              "      <td>street</td>\n",
              "      <td>street</td>\n",
              "      <td>skiing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>orange</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>discuss</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>a</td>\n",
              "      <td>.</td>\n",
              "      <td>a</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>balls</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>topic</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>garden</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>table</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;eos&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                S_1       S_2       S_3  ...     S_30        S_31     S_32\n",
              "Time Steps                               ...                              \n",
              "1             <sos>     <sos>     <sos>  ...    <sos>       <sos>    <sos>\n",
              "2                 a         a        an  ...    group           a        a\n",
              "3              long      girl       old  ...       of         man   female\n",
              "4                 -      with       man  ...    young     wearing    skier\n",
              "5            haired     <unk>  standing  ...   adults       green       in\n",
              "6               man       and    behind  ...     with       jumps        a\n",
              "7                in     metal         a  ...  buckets        with    green\n",
              "8                 a  earrings    basket  ...      and         his     with\n",
              "9              blue    enjoys      full  ...    <unk>  skateboard     pink\n",
              "10            shirt         a        of  ...      wet          in  flowers\n",
              "11          juggles    cherry     green  ...       on         the      hat\n",
              "12              six   indoors    stalks  ...   street      street   skiing\n",
              "13           orange         .         .  ...        .           .        .\n",
              "14            balls     <eos>     <eos>  ...    <eos>       <eos>    <eos>\n",
              "15                .     <pad>     <pad>  ...    <pad>       <pad>    <pad>\n",
              "16            <eos>     <pad>     <pad>  ...    <pad>       <pad>    <pad>\n",
              "\n",
              "[16 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLV-t-MzVQdg"
      },
      "source": [
        "## 用 LSTM 搭建的 Encoder 類別: EncoderLSTM\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dZT3Zs17yMQ",
        "outputId": "5a8718a1-30e7-4580-b137-9de88d50eba6"
      },
      "source": [
        "class EncoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, bidirectional):\n",
        "    super(EncoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    #self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    #self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "    self.tag = True\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    \n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p, bidirectional = bidirectional)\n",
        "\n",
        "  # Shape of x (26, 32) [Sequence_length, batch_size]\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Shape -----------> (26, 32, 300) [Sequence_length , batch_size , embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "    \n",
        "    # Shape --> outputs (26, 32, 1024) [Sequence_length , batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size]\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding)\n",
        "\n",
        "    return hidden_state, cell_state\n",
        "\n",
        "input_size_encoder = len(german.vocab)\n",
        "encoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "encoder_dropout = 0.5\n",
        "bidirectional = True\n",
        "encoder_lstm = EncoderLSTM(input_size_encoder, encoder_embedding_size,\n",
        "              hidden_size, num_layers, encoder_dropout, bidirectional).to(device)\n",
        "print(encoder_lstm)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EncoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(4587, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5, bidirectional=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTew1tbHVer5"
      },
      "source": [
        "## 用 LSTM 搭建的 decoder 類別: DecoderLSTM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPGbQiBP72iX",
        "outputId": "1fd0c66d-b37f-4b8e-8fd4-78357b766b32"
      },
      "source": [
        "class DecoderLSTM(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers, p, output_size, bidirectional):\n",
        "    super(DecoderLSTM, self).__init__()\n",
        "\n",
        "    # Size of the one hot vectors that will be the input to the encoder\n",
        "    #self.input_size = input_size\n",
        "\n",
        "    # Output size of the word embedding NN\n",
        "    #self.embedding_size = embedding_size\n",
        "\n",
        "    # Dimension of the NN's inside the lstm cell/ (hs,cs)'s dimension.\n",
        "    self.hidden_size = hidden_size\n",
        "\n",
        "    # Number of layers in the lstm\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    # Size of the one hot vectors that will be the output to the encoder (English Vocab Size)\n",
        "    self.output_size = output_size\n",
        "\n",
        "    # Regularization parameter\n",
        "    self.dropout = nn.Dropout(p)\n",
        "\n",
        "    # Shape --------------------> (5376, 300) [input size, embedding dims]\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "\n",
        "    # Shape -----------> (300, 2, 1024) [embedding dims, hidden size, num layers]\n",
        "    self.LSTM = nn.LSTM(embedding_size, hidden_size, num_layers, dropout = p, bidirectional = bidirectional)\n",
        "\n",
        "    # Shape -----------> (1024, 4556) [embedding dims, hidden size, num layers]\n",
        "    self.fc = nn.Linear(hidden_size*(int(bidirectional)+1), output_size)\n",
        "\n",
        "  # Shape of x (32) [batch_size]\n",
        "  def forward(self, x, hidden_state, cell_state):\n",
        "\n",
        "    # Shape of x (1, 32) [1, batch_size]\n",
        "    x = x.unsqueeze(0)\n",
        "\n",
        "    # Shape -----------> (1, 32, 300) [1, batch_size, embedding dims]\n",
        "    embedding = self.dropout(self.embedding(x))\n",
        "\n",
        "    # Shape --> outputs (1, 32, 1024) [1, batch_size , hidden_size]\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) , (2, 32, 1024) [num_layers, batch_size size, hidden_size] (passing encoder's hs, cs - context vectors)\n",
        "    outputs, (hidden_state, cell_state) = self.LSTM(embedding, (hidden_state, cell_state))\n",
        "\n",
        "    # Shape --> predictions (1, 32, 4556) [ 1, batch_size , output_size]\n",
        "    predictions = self.fc(outputs)\n",
        "\n",
        "    # Shape --> predictions (32, 4556) [batch_size , output_size]\n",
        "    predictions = predictions.squeeze(0)\n",
        "\n",
        "    return predictions, hidden_state, cell_state\n",
        "\n",
        "input_size_decoder = len(english.vocab)\n",
        "decoder_embedding_size = 300\n",
        "hidden_size = 1024\n",
        "num_layers = 2\n",
        "decoder_dropout = 0.5\n",
        "output_size = len(english.vocab)\n",
        "bidirectional = True\n",
        "decoder_lstm = DecoderLSTM(input_size_decoder, decoder_embedding_size,\n",
        "                           hidden_size, num_layers, decoder_dropout, output_size, bidirectional).to(device)\n",
        "print(decoder_lstm)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DecoderLSTM(\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (embedding): Embedding(4556, 300)\n",
            "  (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5, bidirectional=True)\n",
            "  (fc): Linear(in_features=2048, out_features=4556, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xof3dPly753w",
        "outputId": "a37867b2-f990-42bc-aa34-a9b10cee24cf"
      },
      "source": [
        "for batch in train_iterator:\n",
        "  print(batch.src.shape)\n",
        "  print(batch.trg.shape)\n",
        "  break\n",
        "\n",
        "x = batch.trg[1]\n",
        "print(x)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 32])\n",
            "torch.Size([12, 32])\n",
            "tensor([   4,    4, 1197,    4,   70,    4,    4,    7,    4, 1822,    7,    4,\n",
            "         113,    4,  209,    4,   63,    4,    4,   16,    4,    4,    4,    4,\n",
            "           4,    4,    4,   21,  216,   16,    9,    4], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGnQbCnGVire"
      },
      "source": [
        "# Sequence to Sequence 類別"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_vzOor_Q782h"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, Encoder_LSTM, Decoder_LSTM):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.Encoder_LSTM = Encoder_LSTM\n",
        "    self.Decoder_LSTM = Decoder_LSTM\n",
        "\n",
        "  def forward(self, source, target, tfr=0.5):\n",
        "    # Shape - Source : (10, 32) [(Sentence length german + some padding), Number of Sentences]\n",
        "    batch_size = source.shape[1]\n",
        "\n",
        "    # Shape - Source : (14, 32) [(Sentence length English + some padding), Number of Sentences]\n",
        "    target_len = target.shape[0]\n",
        "    target_vocab_size = len(english.vocab)\n",
        "    \n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "    # Shape --> (hs, cs) (2, 32, 1024) ,(2, 32, 1024) [num_layers, batch_size size, hidden_size] (contains encoder's hs, cs - context vectors)\n",
        "    hidden_state, cell_state = self.Encoder_LSTM(source)\n",
        "\n",
        "    # Shape of x (32 elements)\n",
        "    x = target[0] # Trigger token <SOS>\n",
        "\n",
        "    for i in range(1, target_len):\n",
        "      # Shape --> output (32, 5766) \n",
        "      output, hidden_state, cell_state = self.Decoder_LSTM(x, hidden_state, cell_state)\n",
        "      outputs[i] = output\n",
        "      best_guess = output.argmax(1) # 0th dimension is batch size, 1st dimension is word embedding\n",
        "      x = target[i] if random.random() < tfr else best_guess # Either pass the next word correctly from the dataset or use the earlier predicted word\n",
        "\n",
        "    # Shape --> outputs (14, 32, 5766) \n",
        "    return outputs\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywW6f9fM8AMa"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "learning_rate = 0.001\n",
        "writer = SummaryWriter(f\"runs/loss_plot\")\n",
        "step = 0\n",
        "\n",
        "model = Seq2Seq(encoder_lstm, decoder_lstm).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD0pRilG8CHJ",
        "outputId": "fac6b1a2-7bce-4239-bbeb-ac3c50ad6ceb"
      },
      "source": [
        "model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (Encoder_LSTM): EncoderLSTM(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(4587, 300)\n",
              "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "  )\n",
              "  (Decoder_LSTM): DecoderLSTM(\n",
              "    (dropout): Dropout(p=0.5, inplace=False)\n",
              "    (embedding): Embedding(4556, 300)\n",
              "    (LSTM): LSTM(300, 1024, num_layers=2, dropout=0.5, bidirectional=True)\n",
              "    (fc): Linear(in_features=2048, out_features=4556, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQyZ_vfq8G6C"
      },
      "source": [
        "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
        "    spacy_ger = spacy.load(\"de_core_news_sm\")\n",
        "\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "    tokens.insert(0, german.init_token)\n",
        "    tokens.append(german.eos_token)\n",
        "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    # Build encoder hidden, cell state\n",
        "    with torch.no_grad():\n",
        "        hidden, cell = model.Encoder_LSTM(sentence_tensor)\n",
        "\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        previous_word = torch.LongTensor([outputs[-1]]).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output, hidden, cell = model.Decoder_LSTM(previous_word, hidden, cell)\n",
        "            best_guess = output.argmax(1).item()\n",
        "\n",
        "        outputs.append(best_guess)\n",
        "\n",
        "        # Model predicts it's the end of the sentence\n",
        "        if output.argmax(1).item() == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
        "    return translated_sentence[1:]\n",
        "\n",
        "# 用來評估模型的函式: bleu\n",
        "def bleu(data, model, german, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for example in data:\n",
        "        src = vars(example)[\"src\"]\n",
        "        trg = vars(example)[\"trg\"]\n",
        "\n",
        "        prediction = translate_sentence(model, src, german, english, device)\n",
        "        prediction = prediction[:-1]  # remove <eos> token\n",
        "\n",
        "        targets.append([trg])\n",
        "        outputs.append(prediction)\n",
        "\n",
        "    return bleu_score(outputs, targets)\n",
        "\n",
        "def checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss):\n",
        "    print('saving')\n",
        "    print()\n",
        "    state = {'model': model,'best_loss': best_loss,'epoch': epoch,'rng_state': torch.get_rng_state(), 'optimizer': optimizer.state_dict(),}\n",
        "    torch.save(state, './checkpoint-NMT')\n",
        "    torch.save(model.state_dict(),'./checkpoint-NMT-SD')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysc4A5HX8Qyg",
        "outputId": "13f45d11-a43e-476a-e13a-d16374df14c7"
      },
      "source": [
        "epoch_loss = 0.0\n",
        "num_epochs = 100\n",
        "best_loss = 999999\n",
        "best_epoch = -1\n",
        "sentence1 = \"ein mann in einem blauen hemd steht auf einer leiter und putzt ein fenster\"\n",
        "ts1  = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(\"Epoch - {} / {}\".format(epoch+1, num_epochs))\n",
        "  model.eval()\n",
        "  translated_sentence1 = translate_sentence(model, sentence1, german, english, device, max_length=50)\n",
        "  print(f\"Translated example sentence 1: \\n {translated_sentence1}\")\n",
        "  ts1.append(translated_sentence1)\n",
        "\n",
        "  model.train(True)\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    input = batch.src.to(device)\n",
        "    target = batch.trg.to(device)\n",
        "\n",
        "    # Pass the input and target for model's forward method\n",
        "    output = model(input, target)\n",
        "    output = output[1:].reshape(-1, output.shape[2])\n",
        "    target = target[1:].reshape(-1)\n",
        "\n",
        "    # Clear the accumulating gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Calculate the loss value for every epoch\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # Calculate the gradients for weights & biases using back-propagation\n",
        "    loss.backward()\n",
        "\n",
        "    # Clip the gradient value is it exceeds > 1\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "    # Update the weights values using the gradients we calculated using bp \n",
        "    optimizer.step()\n",
        "    step += 1\n",
        "    epoch_loss += loss.item()\n",
        "    writer.add_scalar(\"Training loss\", loss, global_step=step)\n",
        "\n",
        "  if epoch_loss < best_loss:\n",
        "    best_loss = epoch_loss\n",
        "    best_epoch = epoch\n",
        "    checkpoint_and_save(model, best_loss, epoch, optimizer, epoch_loss) \n",
        "    if ((epoch - best_epoch) >= 10):\n",
        "      print(\"no improvement in 10 epochs, break\")\n",
        "      break\n",
        "  print(\"Epoch_Loss - {}\".format(loss.item()))\n",
        "  print()\n",
        "  \n",
        "print(epoch_loss / len(train_iterator))\n",
        "\n",
        "# score = bleu(test_data[1:100], model, german, english, device)\n",
        "# print(f\"Bleu score {score*100:.2f}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch - 1 / 100\n",
            "Translated example sentence 1: \n",
            " ['bulldozer', 'bulldozer', 'shorts', 'fliers', '.', '.', 'beards', 'umbrellas', 'umbrellas', 'umbrellas', 'kayaking', 'cement', 'speakers', 'speakers', 'released', 'snorkel', 'snorkel', 'officer', 'officer', 'sheep', 'sheep', 'chewing', 'name', 'name', 'speech', 'fellow', 'fellow', 'landmark', 'make', 'thumbs', 'thumbs', 'podium', 'podium', 'podium', 'podium', 'smiling', 'flags', 'flags', 'peacock', 'via', 'umbrellas', 'umbrellas', 'via', 'umbrellas', '.', 'umbrellas', 'cement', 'cement', 'shielding', 'shielding']\n",
            "saving\n",
            "\n",
            "Epoch_Loss - 1.910520315170288\n",
            "\n",
            "Epoch - 2 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 1.1495100259780884\n",
            "\n",
            "Epoch - 3 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.691031813621521\n",
            "\n",
            "Epoch - 4 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.6499719619750977\n",
            "\n",
            "Epoch - 5 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.3053185045719147\n",
            "\n",
            "Epoch - 6 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.23519064486026764\n",
            "\n",
            "Epoch - 7 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.1716117113828659\n",
            "\n",
            "Epoch - 8 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.09974799305200577\n",
            "\n",
            "Epoch - 9 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.1905190348625183\n",
            "\n",
            "Epoch - 10 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.18731951713562012\n",
            "\n",
            "Epoch - 11 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.10264088213443756\n",
            "\n",
            "Epoch - 12 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.10506436973810196\n",
            "\n",
            "Epoch - 13 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.19092726707458496\n",
            "\n",
            "Epoch - 14 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.12456566840410233\n",
            "\n",
            "Epoch - 15 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.6931817531585693\n",
            "\n",
            "Epoch - 16 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.09829734265804291\n",
            "\n",
            "Epoch - 17 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.0958518534898758\n",
            "\n",
            "Epoch - 18 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.1160946860909462\n",
            "\n",
            "Epoch - 19 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.057912860065698624\n",
            "\n",
            "Epoch - 20 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', \"'s\", '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.11402777582406998\n",
            "\n",
            "Epoch - 21 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', 'restaurants', '<eos>']\n",
            "Epoch_Loss - 0.20799271762371063\n",
            "\n",
            "Epoch - 22 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.5783648490905762\n",
            "\n",
            "Epoch - 23 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.03261207789182663\n",
            "\n",
            "Epoch - 24 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.0603569932281971\n",
            "\n",
            "Epoch - 25 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.11465290933847427\n",
            "\n",
            "Epoch - 26 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.09540106356143951\n",
            "\n",
            "Epoch - 27 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.6965917944908142\n",
            "\n",
            "Epoch - 28 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<eos>']\n",
            "Epoch_Loss - 0.35464590787887573\n",
            "\n",
            "Epoch - 29 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', 'restaurants', '.', '<eos>']\n",
            "Epoch_Loss - 0.049336835741996765\n",
            "\n",
            "Epoch - 30 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', \"'s\", '<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.17674940824508667\n",
            "\n",
            "Epoch - 31 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.03712835535407066\n",
            "\n",
            "Epoch - 32 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.04232233762741089\n",
            "\n",
            "Epoch - 33 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.057472582906484604\n",
            "\n",
            "Epoch - 34 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.04507673531770706\n",
            "\n",
            "Epoch - 35 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.1338925063610077\n",
            "\n",
            "Epoch - 36 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<eos>']\n",
            "Epoch_Loss - 0.36363664269447327\n",
            "\n",
            "Epoch - 37 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '!', '.', '<eos>']\n",
            "Epoch_Loss - 0.29765763878822327\n",
            "\n",
            "Epoch - 38 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.04649829864501953\n",
            "\n",
            "Epoch - 39 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.14515377581119537\n",
            "\n",
            "Epoch - 40 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.27579358220100403\n",
            "\n",
            "Epoch - 41 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.08272421360015869\n",
            "\n",
            "Epoch - 42 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.04765669256448746\n",
            "\n",
            "Epoch - 43 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.029459357261657715\n",
            "\n",
            "Epoch - 44 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', \"'s\", '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.026198964565992355\n",
            "\n",
            "Epoch - 45 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.06605950742959976\n",
            "\n",
            "Epoch - 46 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.07504354417324066\n",
            "\n",
            "Epoch - 47 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.03515767306089401\n",
            "\n",
            "Epoch - 48 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.02846515364944935\n",
            "\n",
            "Epoch - 49 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.2692362368106842\n",
            "\n",
            "Epoch - 50 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 't', '-', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.1096239984035492\n",
            "\n",
            "Epoch - 51 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.5048226118087769\n",
            "\n",
            "Epoch - 52 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.07492265105247498\n",
            "\n",
            "Epoch - 53 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.05216294899582863\n",
            "\n",
            "Epoch - 54 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.1757882833480835\n",
            "\n",
            "Epoch - 55 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', 'restaurants', '<eos>']\n",
            "Epoch_Loss - 0.33232763409614563\n",
            "\n",
            "Epoch - 56 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.05121886730194092\n",
            "\n",
            "Epoch - 57 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', \"'s\", '.', '<eos>']\n",
            "Epoch_Loss - 0.08104763925075531\n",
            "\n",
            "Epoch - 58 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.09993750602006912\n",
            "\n",
            "Epoch - 59 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.059728920459747314\n",
            "\n",
            "Epoch - 60 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', \"'s\", '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.29974985122680664\n",
            "\n",
            "Epoch - 61 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.06933977454900742\n",
            "\n",
            "Epoch - 62 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.16205734014511108\n",
            "\n",
            "Epoch - 63 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.27105483412742615\n",
            "\n",
            "Epoch - 64 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.06320640444755554\n",
            "\n",
            "Epoch - 65 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', 'in', '<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.023582693189382553\n",
            "\n",
            "Epoch - 66 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.032371100038290024\n",
            "\n",
            "Epoch - 67 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.048370059579610825\n",
            "\n",
            "Epoch - 68 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.05701350420713425\n",
            "\n",
            "Epoch - 69 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'knee', '-', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.03188155218958855\n",
            "\n",
            "Epoch - 70 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.05198952183127403\n",
            "\n",
            "Epoch - 71 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.053240999579429626\n",
            "\n",
            "Epoch - 72 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.055812813341617584\n",
            "\n",
            "Epoch - 73 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.03915833309292793\n",
            "\n",
            "Epoch - 74 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.11961701512336731\n",
            "\n",
            "Epoch - 75 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.04692315682768822\n",
            "\n",
            "Epoch - 76 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.1442001461982727\n",
            "\n",
            "Epoch - 77 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.09419029206037521\n",
            "\n",
            "Epoch - 78 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'powered', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.0675058364868164\n",
            "\n",
            "Epoch - 79 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.034733016043901443\n",
            "\n",
            "Epoch - 80 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.06527384370565414\n",
            "\n",
            "Epoch - 81 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'robes', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.044568102806806564\n",
            "\n",
            "Epoch - 82 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', 'of', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.02884875237941742\n",
            "\n",
            "Epoch - 83 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', 'first', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.059057433158159256\n",
            "\n",
            "Epoch - 84 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'strange', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.0452403724193573\n",
            "\n",
            "Epoch - 85 / 100\n",
            "Translated example sentence 1: \n",
            " ['veteran', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.09784684330224991\n",
            "\n",
            "Epoch - 86 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'knee', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.22220094501972198\n",
            "\n",
            "Epoch - 87 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'knee', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.06909043341875076\n",
            "\n",
            "Epoch - 88 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'knee', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.10053878277540207\n",
            "\n",
            "Epoch - 89 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'knee', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.09419192373752594\n",
            "\n",
            "Epoch - 90 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', 'strange', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.17342473566532135\n",
            "\n",
            "Epoch - 91 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.024130307137966156\n",
            "\n",
            "Epoch - 92 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', 't', '-', 'shirt', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.1456678807735443\n",
            "\n",
            "Epoch - 93 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', \"'s\", '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.03751816973090172\n",
            "\n",
            "Epoch - 94 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'if', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.2829877436161041\n",
            "\n",
            "Epoch - 95 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.030732672661542892\n",
            "\n",
            "Epoch - 96 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', 'kitty', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '.', '<eos>']\n",
            "Epoch_Loss - 0.0455627366900444\n",
            "\n",
            "Epoch - 97 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.20721858739852905\n",
            "\n",
            "Epoch - 98 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '.', '<eos>']\n",
            "Epoch_Loss - 0.04027165099978447\n",
            "\n",
            "Epoch - 99 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<eos>']\n",
            "Epoch_Loss - 0.8699447512626648\n",
            "\n",
            "Epoch - 100 / 100\n",
            "Translated example sentence 1: \n",
            " ['<unk>', '<unk>', 'in', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '2', '<eos>']\n",
            "Epoch_Loss - 0.021767864003777504\n",
            "\n",
            "17.396264527081215\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHKQ9GpPS39_"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}