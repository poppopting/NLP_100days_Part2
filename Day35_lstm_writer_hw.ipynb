{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSmJJczZo5zp"
   },
   "source": [
    "# 專題（一）：訓練LSTM之歌詞自動填詞器\n",
    "\n",
    "## 專案目標\n",
    "- 目標：使用 LSTM 模型去學習五月天歌詞，並且可以自動填詞來產生歌詞\n",
    "- mayday_lyrics.txt 資料說明：\n",
    "    - 每一行都是一首歌的歌詞\n",
    "    - 除去標點符號並以空白表示間格\n",
    "- 利用 mayday_lyrics.txt 來產生歌詞的序列\n",
    "- 使用 LSTM 模型去學習歌詞的序列\n",
    "- 當我們給定開頭的一段歌詞，例如：”給我一首歌”，就可以用 LSTM 猜下一個字，反覆這個過程就可以自動填詞\n",
    "\n",
    "## 實作提示\n",
    "- STEP1：從 mayday_lyrics.txt 中取出歌詞\n",
    "- STEP2：建立每個字的 Index\n",
    "- STEP3：用 Rolling 的方式打造 LyricsDataset\n",
    "- STEP4：使用 DataLoader 來包裝 LyricsDataset\n",
    "- STEP5：建立 LSTM 模型： inputs > nn.Embedding > nn.LSTM > nn.Dropout > 取最後一個 state > nn.Linear > softmax\n",
    "- STEP6：開始訓練並調整參數\n",
    "- STEP7：進行 Demo，給定 pre_text ，使用模型迭代的預測下一個字產生歌詞\n",
    "- (進階) STEP8：在 Demo 時可以採用依照 Softmax 機率來作隨機採樣，這可以增加隨機性，讓歌詞有更多變化，當然你還可以使用機率閥值來避免太奇怪的字出現\n",
    "\n",
    "## 重要知識點：專題結束後你可以學會\n",
    "- 如何讀取並處理需要 Rolling 的序列資料\n",
    "- 了解如何用 Pytorch 建制一個 LSTM 的模型\n",
    "- 學會如何訓練一個語言模型\n",
    "- 學會如何隨機抽樣自 Softmax 的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hen1MQ1F_cly"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7joX8NEEu90J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "摸不到的顏色 是否叫彩虹 看不到的擁抱 是否叫做微風 一個人 想著一個人 是否就叫寂寞 命運偷走如果 只留下結果 時間偷走初衷 只留下了苦衷 你來過 然後你走後 只留下星空 那一年我們望著星空 有那麼多的燦爛的夢 以為快樂會永久 像不變星空 陪著我 獵戶 天狼 織女光年外沈默 回憶 青春 夢想何時偷偷隕落 我愛過 然後我沈默 人海裡漂流 那一年我們望著星空 未來的未來從沒想過 當故事失去美夢 美夢失去線索 而我們失去聯絡 這一片無言無語星空 為什麼靜靜看我淚流 如果你在的時候 會不會伸手 擁抱我 細數繁星閃爍 細數此生奔波 原來所有 所得 所獲 不如一夜的星空 空氣中的溫柔 回憶你的笑容 徬佛只要伸手 就能觸摸 摸不到的顏色 是否叫彩虹 看不到的擁抱 是否叫做微風 一個人 習慣一個人 這一刻獨自望著星空 從前的從前從沒變過 寂寞可以是忍受 也可以是享受 享受僅有的擁有 那一年我們望著星空 有那麼多的燦爛的夢 至少回憶會永久 像不變星空 陪著我 最後只剩下星空 像不變回憶 陪著我\n"
     ]
    }
   ],
   "source": [
    "# from: https://github.com/gaussic/Chinese-Lyric-Corpus\n",
    "lyrics_list = [line.strip() for line in open('mayday_lyrics.txt', encoding='utf-8')]\n",
    "print(lyrics_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_P3Bonv_7FpS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2101\n"
     ]
    }
   ],
   "source": [
    "# 建立詞典對照表\n",
    "word2index = {}\n",
    "index2word = {}\n",
    "\n",
    "i = 0\n",
    "for words in lyrics_list:\n",
    "    for word in words:\n",
    "        if word not in word2index:\n",
    "            word2index[word] = i\n",
    "            index2word[i] = word\n",
    "            i += 1\n",
    "print(len(word2index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "BwIpjwU_8YJB"
   },
   "outputs": [],
   "source": [
    "# 建立數據集\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics_list, word2index, num_unrollings=10):\n",
    "        self.word2index = word2index\n",
    "        self.num_unrollings = num_unrollings\n",
    "        \n",
    "        self.gen_rolling_samples(lyrics_list, num_unrollings)\n",
    "    \n",
    "    def gen_rolling_samples(self, lyrics_list, num_unrollings):\n",
    "        self.samples = []\n",
    "        for lyrics in lyrics_list:\n",
    "            for i in range(len(lyrics)-self.num_unrollings+1):\n",
    "                self.samples.append(lyrics[i:i+num_unrollings])\n",
    "        return self\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        inputs = [self.word2index[i] for i in sample[:-1]]\n",
    "        targets = [self.word2index[sample[-1]]]\n",
    "\n",
    "        return torch.LongTensor(inputs), torch.LongTensor(targets)\n",
    "    def __len__(self):\n",
    "        return len(self.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_L7UokS6_W7O"
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataset = LyricsDataset(lyrics_list, word2index)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "class LM_LSTM(nn.Module):\n",
    "    def __init__(self, n_hidden, vocab_size, num_layers, dropout_ratio):\n",
    "        super(LM_LSTM, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, n_hidden)\n",
    "        self.lstm = nn.LSTM(input_size=n_hidden,\n",
    "                            hidden_size=n_hidden,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True)\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "        self.fc = nn.Linear(n_hidden, vocab_size)\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        embedd_inputs = self.embedding(inputs) # [batch, seq_len, hidden]\n",
    "        out, (hn, cn) = self.lstm(embedd_inputs)  # [batch, seq_len, hidden]\n",
    "        out = self.dropout(out)  # [batch, seq_len, hidden]\n",
    "        out = self.fc(out[:,-1,:])  # [batch, hidden]\n",
    "        return out # [batch, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-tNgfswV_nc1"
   },
   "outputs": [],
   "source": [
    "def train_batch(model, data, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    inputs, targets = [d.to(device) for d in data]\n",
    "\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    loss = criterion(outputs, targets.squeeze())\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_QVIJqHRsnX",
    "outputId": "3ad0be24-37a2-463c-90db-206ca71f8251"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guan-Ting Chen\\Anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 train_loss:  5.643004514598451\n",
      "epoch  2 train_loss:  5.196324539124573\n",
      "epoch  3 train_loss:  4.86555885632394\n",
      "epoch  4 train_loss:  4.567099129264321\n",
      "epoch  5 train_loss:  4.292098639372742\n",
      "epoch  6 train_loss:  4.03704795566081\n",
      "epoch  7 train_loss:  3.796037594787044\n",
      "epoch  8 train_loss:  3.5687444632658725\n",
      "epoch  9 train_loss:  3.34744874788131\n",
      "epoch  10 train_loss:  3.139166412772164\n",
      "Example: \"摸不到的顏色 是否\"+\"不\"\n",
      "Example: \" 只留下結果 時間\"+\"一\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  11 train_loss:  2.9442380403473645\n",
      "epoch  12 train_loss:  2.759889897148055\n",
      "epoch  13 train_loss:  2.5772094532571113\n",
      "epoch  14 train_loss:  2.4148118650892614\n",
      "epoch  15 train_loss:  2.2523768276177734\n",
      "epoch  16 train_loss:  2.106998293060201\n",
      "epoch  17 train_loss:  1.975037826106905\n",
      "epoch  18 train_loss:  1.8484715906927853\n",
      "epoch  19 train_loss:  1.7249181839199115\n",
      "epoch  20 train_loss:  1.6136352818783413\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"的\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  21 train_loss:  1.514967200694534\n",
      "epoch  22 train_loss:  1.41815704693821\n",
      "epoch  23 train_loss:  1.3327736458987456\n",
      "epoch  24 train_loss:  1.2552282788587141\n",
      "epoch  25 train_loss:  1.1833824921814244\n",
      "epoch  26 train_loss:  1.1076492716852226\n",
      "epoch  27 train_loss:  1.041616451127167\n",
      "epoch  28 train_loss:  0.9811935048738054\n",
      "epoch  29 train_loss:  0.9286361385591315\n",
      "epoch  30 train_loss:  0.8776741672136753\n",
      "Example: \"摸不到的顏色 是否\"+\"給\"\n",
      "Example: \" 只留下結果 時間\"+\"一\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  31 train_loss:  0.8284142780830598\n",
      "epoch  32 train_loss:  0.7876121212826446\n",
      "epoch  33 train_loss:  0.7455886080758232\n",
      "epoch  34 train_loss:  0.7099569725927382\n",
      "epoch  35 train_loss:  0.6714295699970847\n",
      "epoch  36 train_loss:  0.6369436826092293\n",
      "epoch  37 train_loss:  0.6083213437068734\n",
      "epoch  38 train_loss:  0.5776232062542224\n",
      "epoch  39 train_loss:  0.5567644255346236\n",
      "epoch  40 train_loss:  0.5287726568271177\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"就\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  41 train_loss:  0.5012919314535971\n",
      "epoch  42 train_loss:  0.482273250400042\n",
      "epoch  43 train_loss:  0.4626963047001056\n",
      "epoch  44 train_loss:  0.44544472048259\n",
      "epoch  45 train_loss:  0.43330172295151476\n",
      "epoch  46 train_loss:  0.4143489248639307\n",
      "epoch  47 train_loss:  0.3994650248605886\n",
      "epoch  48 train_loss:  0.3807053644142199\n",
      "epoch  49 train_loss:  0.36898324842619495\n",
      "epoch  50 train_loss:  0.3637909192106315\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"一\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  51 train_loss:  0.3497705767075864\n",
      "epoch  52 train_loss:  0.3418674844560796\n",
      "epoch  53 train_loss:  0.3240196345901276\n",
      "epoch  54 train_loss:  0.3169753217776619\n",
      "epoch  55 train_loss:  0.30446512277573\n",
      "epoch  56 train_loss:  0.3010160632558715\n",
      "epoch  57 train_loss:  0.29565352111778276\n",
      "epoch  58 train_loss:  0.2950860085216628\n",
      "epoch  59 train_loss:  0.28594532465294364\n",
      "epoch  60 train_loss:  0.26761438699178014\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  61 train_loss:  0.2672419049098491\n",
      "epoch  62 train_loss:  0.2675450162528928\n",
      "epoch  63 train_loss:  0.2657191950462033\n",
      "epoch  64 train_loss:  0.2589769115247674\n",
      "epoch  65 train_loss:  0.24476039233603603\n",
      "epoch  66 train_loss:  0.24421051675045108\n",
      "epoch  67 train_loss:  0.2387137717261392\n",
      "epoch  68 train_loss:  0.23406435834480896\n",
      "epoch  69 train_loss:  0.23498381064030346\n",
      "epoch  70 train_loss:  0.22825019672658053\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  71 train_loss:  0.2295356178130365\n",
      "epoch  72 train_loss:  0.21864983319815393\n",
      "epoch  73 train_loss:  0.2192214139073693\n",
      "epoch  74 train_loss:  0.21975065631495055\n",
      "epoch  75 train_loss:  0.22010929848908098\n",
      "epoch  76 train_loss:  0.21830611249212803\n",
      "epoch  77 train_loss:  0.2020011393723867\n",
      "epoch  78 train_loss:  0.19785564584840842\n",
      "epoch  79 train_loss:  0.20799616465058482\n",
      "epoch  80 train_loss:  0.20658811759531456\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  81 train_loss:  0.19841716631609238\n",
      "epoch  82 train_loss:  0.20082259172745195\n",
      "epoch  83 train_loss:  0.1974868238958674\n",
      "epoch  84 train_loss:  0.19255445434657043\n",
      "epoch  85 train_loss:  0.18907946765984254\n",
      "epoch  86 train_loss:  0.19464830653264925\n",
      "epoch  87 train_loss:  0.18949006451742212\n",
      "epoch  88 train_loss:  0.1803184241416322\n",
      "epoch  89 train_loss:  0.18451592274447792\n",
      "epoch  90 train_loss:  0.1885669151710001\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n",
      "epoch  91 train_loss:  0.18522699774764675\n",
      "epoch  92 train_loss:  0.182230685928139\n",
      "epoch  93 train_loss:  0.18141239678503684\n",
      "epoch  94 train_loss:  0.17745414486149805\n",
      "epoch  95 train_loss:  0.18027099459473322\n",
      "epoch  96 train_loss:  0.18769353900958954\n",
      "epoch  97 train_loss:  0.18101644190224428\n",
      "epoch  98 train_loss:  0.177683460619312\n",
      "epoch  99 train_loss:  0.16709167584239143\n",
      "epoch  100 train_loss:  0.1660608643827003\n",
      "Example: \"摸不到的顏色 是否\"+\"叫\"\n",
      "Example: \" 只留下結果 時間\"+\"偷\"\n",
      "Example: \"麼多的燦爛的夢 以\"+\"為\"\n"
     ]
    }
   ],
   "source": [
    "# 訓練模型\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LM_LSTM(128, len(word2index), 2, 0.2)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(size_average=False)\n",
    "criterion.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(1, 1 + epochs):\n",
    "    tot_train_loss = 0\n",
    "    tot_train_count = 0\n",
    "\n",
    "    for train_data in train_loader:\n",
    "        loss = train_batch(model, train_data, criterion, optimizer, device)\n",
    "\n",
    "        tot_train_loss += loss\n",
    "        tot_train_count += train_data[0].size(0)\n",
    "\n",
    "    print('epoch ', epoch, 'train_loss: ', tot_train_loss / tot_train_count)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        for idx in [0, 50, 99]:\n",
    "            input_batch = dataset[idx][0].unsqueeze(0).to(device)\n",
    "            predict = model(input_batch).argmax(dim=-1).item()\n",
    "            print('Example: \"{}\"+\"{}\"'.format(dataset.samples[idx][:-1], index2word[predict]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "anMER7TJTWKy",
    "outputId": "8ad0434c-91ee-4542-cc3a-bf881d2fb379"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "給我一首歌 世界曾經人有殘忍 我的每一個眼眶 當純的洗衣機 高中的狂雨 多無聊 原定都再溫柔 誰想念影吧 突然\n"
     ]
    }
   ],
   "source": [
    "# 模型inference\n",
    "pre_text = '給我一首歌'\n",
    "generate_len = 50\n",
    "prob_threshold = 0.01\n",
    "\n",
    "result = [word2index[c] for c in pre_text]\n",
    "for _ in range(generate_len):\n",
    "    input_example = torch.tensor([result], dtype=torch.long, device=device)\n",
    "    logit = model(input_example)\n",
    "\n",
    "    logit = F.softmax(logit, dim=1)\n",
    "    logit[logit<=prob_threshold] = 0. \n",
    "    predict = torch.multinomial(logit, 1).item()\n",
    "\n",
    "    ## End\n",
    "    result += [predict]\n",
    "print(''.join([index2word[i] for i in result]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_writer_hw.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
